% brute force
% param : features - 
%         labels - 
%         hyperparameters - pre-set hyper parameters used to evaluate
%         kernal_method - 'rbf' or 'polynomial'
%         k_fold - 
function [optimise_hyperparameters, support_vector_stats, opt_rmse] = GridSearchCV(features, labels, hyperparameters, kernal_method, k_fold)

    % sigma for RBF and q for the polynomial kernel; box-constraint C
    optimise_hyperparameters = zeros(1:2);
    
    % here we create a 2-d matrix, but actually we want a 3-d matrix,
    % the way to track the value: 
    %       svs(hp, k_fold, 1) is number of support vector
    %       svs(hp, k_fold, 2) is a % of the training data
    %           where hp is hyperparameters we used.
    support_vector_stats = zerors(size(hyperparameters, 1), k_fold);
    
    opt_rmse = Inf;
    data_size = size(labels, 1);

    for i = 1:size(hyperparameters, 1)
        % Two different kernal functions: rbf and polynomial
        mdl = fitcsvm(features, labels, 'KernelFunction',kernal_method, 'KernelScale', hyperparameters(i, 1), 'BoxConstraint', hyperparameters(i, 2) , 'Standardize', true, 'KFold', k_fold);

        for k = 1 : k_fold
            support_vector_stats(i, k, 1) = length(mdl.Trained{n, 1}.SupportVectors);
            support_vector_stats(i, k, 2) = support_vector_stats(i, k, 1) / data_size;
        end
        
        rmse = sqrt(kfoldLoss(mdl));
        
        if (rmse <= opt_rmse)
            optimise_hyperparameters(:) = hyperparameters(i, :);
            opt_rmse = rmse;
        end
    end
end


% random
function [optimise_hyperparameters, support_vector_stats, opt_rmse] = RandomizedSearchCV(features, labels, param_distributions, n_iter, kernal_method, k_fold)

    % same to GridSearchCV
    optimise_hyperparameters = zeros(1:2);
    support_vector_stats = zerors(n_iter, k_fold);
    
    opt_rmse = Inf;
    data_size = size(labels, 1);

    for i = 1:size(hyperparameters, 1)
        % Two different kernal functions: rbf and polynomial
        mdl = fitcsvm(features, labels, 'KernelFunction',kernal_method, 'KernelScale', hyperparameters(i, 1), 'BoxConstraint', hyperparameters(i, 2) , 'Standardize', true, 'KFold', k_fold);

        for k = 1 : k_fold
            support_vector_stats(i, k, 1) = length(mdl.Trained{n, 1}.SupportVectors);
            support_vector_stats(i, k, 2) = support_vector_stats(i, k, 1) / data_size;
        end
        
        rmse = sqrt(kfoldLoss(mdl));
        
        if (rmse <= opt_rmse)
            optimise_hyperparameters(:) = hyperparameters(i, :);
            opt_rmse = rmse;
        end
    end
end